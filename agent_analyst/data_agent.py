import os
import pandas as pd
from typing import List, Optional
import google.generativeai as genai


class DataAnalysisAgent:
    def __init__(self, df_list: List[pd.DataFrame], df_names: List[str]):
        """
        Vers√£o atualizada para usar a API oficial do Gemini sem thinking_config
        """
        if not df_list:
            raise ValueError("A lista de dataframes n√£o pode ser vazia.")

        # Configura√ß√£o do cliente Gemini
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("Vari√°vel GEMINI_API_KEY n√£o encontrada no .env")

        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-1.5-flash')
        self.df_list = df_list
        self.df_names = df_names
        self._prepare_data_context()

    def _prepare_data_context(self):
        """Prepara um resumo dos dataframes para incluir no contexto"""
        self.data_context = "\n".join(
            f"- {name}: {len(df)} linhas, {len(df.columns)} colunas. Colunas: {', '.join(df.columns)}"
            for name, df in zip(self.df_names, self.df_list)
        )

    @staticmethod
    def load_data(path: str) -> Optional[pd.DataFrame]:
        """Carrega dados com tratamento robusto de erros"""
        try:
            df = pd.read_csv(path, sep=',', decimal='.')
            print(f"‚úÖ Dados carregados: {path}")
            return df
        except Exception as e:
            print(f"‚ùå Erro ao carregar {path}: {str(e)}")
            return None

    def _generate_prompt(self, question: str) -> str:
        """Gera o prompt contextualizado com os dataframes"""
        return f"""
        Voc√™ √© um analista de dados especializado em notas fiscais. 
        Voc√™ tem acesso aos seguintes dataframes:

        {self.data_context}

        Relacione os dataframes pela coluna 'CHAVE DE ACESSO' quando necess√°rio.

        Responda a seguinte pergunta:
        {question}

        Forne√ßa:
        1. Uma explica√ß√£o clara
        2. O c√≥digo pandas usado para obter a resposta (se aplic√°vel)
        3. A resposta final formatada
        """

    def run_query(self, question: str) -> Optional[str]:
        """Executa consulta usando a API do Gemini"""
        try:
            prompt = self._generate_prompt(question)
            print(f"\nüîç Processando: {question[:50]}...")

            response = self.model.generate_content(prompt)

            if not response.text:
                raise ValueError("Resposta vazia do Gemini")

            return response.text

        except Exception as e:
            print(f"‚ùå Erro na consulta: {str(e)}")
            return None